{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33293d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /path/to/workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import warnings\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "from IPython.display import display, Audio\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from modeling_bailingmm import BailingMMNativeForConditionalGeneration\n",
    "from sentence_manager.sentence_manager import SentenceNormalizer\n",
    "from spkemb_extractor import SpkembExtractor\n",
    "\n",
    "\n",
    "def seed_everything(seed=1895):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "BASE_CAPTION_TEMPLATE = {\n",
    "    \"audio_sequence\": [\n",
    "        {\n",
    "            \"序号\": 1,\n",
    "            \"说话人\": \"speaker_1\",\n",
    "            \"方言\": None,\n",
    "            \"风格\": None,\n",
    "            \"语速\": None,\n",
    "            \"基频\": None,\n",
    "            \"音量\": None,\n",
    "            \"情感\": None,\n",
    "            \"BGM\": {\n",
    "                \"Genre\": None,\n",
    "                \"Mood\": None,\n",
    "                \"Instrument\": None,\n",
    "                \"Theme\": None,\n",
    "                \"ENV\": None,\n",
    "                \"SNR\": None,\n",
    "\n",
    "            },\n",
    "            \"IP\": None,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "class MingAudio:\n",
    "    def __init__(self, model_path, device=\"cuda:0\"):\n",
    "        self.device = device\n",
    "        self.model = BailingMMNativeForConditionalGeneration.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            low_cpu_mem_usage=True,\n",
    "        )\n",
    "        self.model = self.model.eval().to(torch.bfloat16).to(self.device)\n",
    "\n",
    "        if self.model.model_type == 'dense':\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        else:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\".\", trust_remote_code=True)\n",
    "        self.model.tokenizer = self.tokenizer\n",
    "        self.sample_rate = self.model.config.audio_tokenizer_config.sample_rate\n",
    "        self.patch_size = self.model.config.ditar_config['patch_size']\n",
    "        self.normalizer = self.init_tn_normalizer(tokenizer=self.tokenizer)\n",
    "\n",
    "        local_model_path = model_path if os.path.isdir(model_path) else snapshot_download(repo_id=model_path)\n",
    "        self.spkemb_extractor = SpkembExtractor(f\"{local_model_path}/campplus.onnx\")\n",
    "\n",
    "\n",
    "    def init_tn_normalizer(self, config_file_path=None, tokenizer=None):\n",
    "        if config_file_path is None:\n",
    "            default_config_path = \"sentence_manager/default_config.yaml\"\n",
    "            config_file_path = default_config_path\n",
    "\n",
    "        with open(config_file_path, 'r') as f:\n",
    "            self.sentence_manager_config = yaml.safe_load(f)\n",
    "\n",
    "        if \"split_token\" not in self.sentence_manager_config:\n",
    "            self.sentence_manager_config[\"split_token\"] = []\n",
    "\n",
    "        assert isinstance(self.sentence_manager_config[\"split_token\"], list)\n",
    "        if tokenizer is not None:\n",
    "            self.sentence_manager_config[\"split_token\"].append(re.escape(tokenizer.eos_token))\n",
    "\n",
    "        normalizer = SentenceNormalizer(self.sentence_manager_config.get(\"text_norm\", {}))\n",
    "\n",
    "        return normalizer\n",
    "\n",
    "    def create_instruction(self, user_input: dict):\n",
    "        new_caption = copy.deepcopy(BASE_CAPTION_TEMPLATE)\n",
    "        target_item_dict = new_caption[\"audio_sequence\"][0]\n",
    "\n",
    "        for key, value in user_input.items():\n",
    "            if key in target_item_dict:\n",
    "                target_item_dict[key] = value\n",
    "\n",
    "        if target_item_dict[\"BGM\"].get(\"SNR\", None) is not None:\n",
    "            new_order = [\"序号\", \"说话人\", \"BGM\", \"情感\", \"方言\", \"风格\", \"语速\", \"基频\", \"音量\", \"IP\"]\n",
    "            target_item_dict = {k: target_item_dict[k] for k in new_order if k in target_item_dict}\n",
    "            new_caption[\"audio_sequence\"][0] = target_item_dict\n",
    "\n",
    "        return new_caption\n",
    "\n",
    "    def pad_waveform(self, waveform):\n",
    "        # Pad the prompt_waveform to ensure its length is a multiple of the patch size. 12.5 for tokenizer framerate.\n",
    "        pad_align = int(1 / 12.5 * self.patch_size * self.sample_rate)\n",
    "        new_len = (waveform.size(-1) + pad_align - 1) // pad_align * pad_align\n",
    "        if new_len != waveform.size(1):\n",
    "            new_wav = torch.zeros(1, new_len, dtype=waveform.dtype, device=waveform.device)\n",
    "            new_wav[:, :waveform.size(1)] = waveform.clone()\n",
    "            waveform = new_wav\n",
    "        return waveform\n",
    "\n",
    "    def preprocess_one_prompt_wav(self, waveform_path, use_spk_emb):\n",
    "        if waveform_path is None:\n",
    "            return None, None\n",
    "\n",
    "        waveform, sr = torchaudio.load(waveform_path)\n",
    "        waveform1 = waveform.clone()\n",
    "        if sr != self.sample_rate:\n",
    "            waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.sample_rate)(waveform)\n",
    "\n",
    "        if use_spk_emb:\n",
    "            waveform1 = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(waveform1)\n",
    "            spk_emb = self.spkemb_extractor(waveform1)\n",
    "        else:\n",
    "            spk_emb = None\n",
    "        return waveform, spk_emb\n",
    "\n",
    "    def speech_generation(\n",
    "        self,\n",
    "        prompt,\n",
    "        text,\n",
    "        use_spk_emb=False,\n",
    "        use_zero_spk_emb=False,\n",
    "        instruction=None,\n",
    "        prompt_wav_path=None,\n",
    "        prompt_text=None,\n",
    "        max_decode_steps=200,\n",
    "        cfg=2.0,\n",
    "        sigma=0.25,\n",
    "        temperature=0,\n",
    "        output_wav_path='./out.wav'\n",
    "    ):\n",
    "        # text = self.normalizer.normalize(text)\n",
    "        if prompt_wav_path is None:\n",
    "            prompt_waveform, prompt_text, spk_emb = None, None, None\n",
    "            if use_zero_spk_emb:\n",
    "                spk_emb = [torch.zeros(1, 192, device=self.device, dtype=torch.bfloat16)]\n",
    "        else:\n",
    "            paths = prompt_wav_path if isinstance(prompt_wav_path, list) else [prompt_wav_path]\n",
    "            processed_prompts = [self.preprocess_one_prompt_wav(p, use_spk_emb) for p in paths]\n",
    "            waveforms_list, spk_emb = zip(*processed_prompts)\n",
    "            prompt_waveform = torch.cat(waveforms_list, dim=-1)\n",
    "            prompt_waveform = self.pad_waveform(prompt_waveform)\n",
    "            spk_emb = list(spk_emb)\n",
    "            if all([x is None for x in spk_emb]):\n",
    "                spk_emb = None\n",
    "\n",
    "        if instruction is not None:\n",
    "            instruction = self.create_instruction(instruction)\n",
    "            instruction = json.dumps(instruction, ensure_ascii=False)\n",
    "\n",
    "        waveform = self.model.generate(\n",
    "            prompt=prompt,\n",
    "            text=text,\n",
    "            spk_emb=spk_emb,\n",
    "            instruction=instruction,\n",
    "            prompt_waveform=prompt_waveform,\n",
    "            prompt_text=prompt_text,\n",
    "            max_decode_steps=max_decode_steps,\n",
    "            cfg=cfg,\n",
    "            sigma=sigma,\n",
    "            temperature=temperature,\n",
    "            use_zero_spk_emb=use_zero_spk_emb\n",
    "        )\n",
    "        if output_wav_path is not None:\n",
    "            output_dir = os.path.dirname(output_wav_path)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            torchaudio.save(output_wav_path, waveform, sample_rate=self.sample_rate)\n",
    "        return waveform\n",
    "\n",
    "    def generation(\n",
    "            self,\n",
    "            prompt,\n",
    "            text,\n",
    "            max_decode_steps=200,\n",
    "        ):\n",
    "            text = self.model.generate_text(\n",
    "                prompt=prompt,\n",
    "                text=text,\n",
    "                max_decode_steps=max_decode_steps,\n",
    "            )\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "model = MingAudio(\"inclusionAI/Ming-omni-tts-0.5B\")\n",
    "# model = MingAudio(\"inclusionAI/Ming-omni-tts-16.8B-A3B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "libroFormatter": "formatter-string"
   },
   "source": [
    "# Zero-shot voice clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 200,\n",
    "}\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate speech based on the following description.\\n\",\n",
    "    \"text\": \"我们的愿景是构建未来服务业的数字化基础设施，为世界带来更多微小而美好的改变。\",\n",
    "    \"use_spk_emb\": True,\n",
    "    \"prompt_wav_path\": \"data/wavs/10002287-00000094.wav\",\n",
    "    \"prompt_text\": \"在此奉劝大家别乱打美白针。\"\n",
    "}\n",
    "\n",
    "response = model.speech_generation(**messages, **decode_args, output_wav_path='output/tts.wav')\n",
    "logger.info(f\"Generated Response: {response}\")\n",
    "display(Audio('output/tts.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1dab3",
   "metadata": {},
   "source": [
    "# Speech basic attribute control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 200,\n",
    "}\n",
    "instruction = {\n",
    "    \"语速\": \"快速\",\n",
    "    \"基频\": \"中\",\n",
    "    \"音量\": \"高\",\n",
    "}\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate speech based on the following description.\\n\",\n",
    "    \"text\": \"简单地说，这相当于惠普把消费领域市场拱手相让了。\",\n",
    "    \"use_spk_emb\": True,\n",
    "    \"instruction\": instruction,\n",
    "    \"prompt_wav_path\": \"data/wavs/10002287-00000095.wav\",\n",
    "}\n",
    "\n",
    "response =  model.speech_generation(**messages, **decode_args, output_wav_path='output/basic.wav')\n",
    "display(Audio('output/basic.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Speech Control - Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 200,\n",
    "}\n",
    "instruction = {\n",
    "    \"情感\": \"高兴\"\n",
    "}\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate speech based on the following description.\\n\",\n",
    "    \"text\": \"我竟然抢到了陈奕迅的演唱会门票！太棒了！终于可以现场听一听他的歌声了！\",\n",
    "    \"use_spk_emb\": True,\n",
    "    \"instruction\": instruction,\n",
    "    \"prompt_wav_path\": \"data/wavs/emotion_prompt.wav\",\n",
    "}\n",
    "response = model.speech_generation(**messages, **decode_args, output_wav_path='output/emotion.wav')\n",
    "display(Audio('output/emotion.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Speech Control - Dialect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 200\n",
    "}\n",
    "instruction = {\n",
    "    \"方言\": \"广粤话\"\n",
    "}\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate speech based on the following description.\\n\",\n",
    "    \"text\": \"我觉得社会企业同个人都有责任\",\n",
    "    \"use_spk_emb\": True,\n",
    "    \"instruction\": instruction,\n",
    "    \"prompt_wav_path\": \"data/wavs/yue_prompt.wav\",\n",
    "}\n",
    "response =  model.speech_generation(**messages, **decode_args, output_wav_path='output/yue.wav')\n",
    "display(Audio('output/yue.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 200,\n",
    "}\n",
    "dialog = [\n",
    "    {\"speaker_1\": \"你可以说一下，就大概说一下，可能虽然我也不知道，我看过那部电影没有。\"},\n",
    "    {\"speaker_2\": \"就是那个叫什么，变相一节课的嘛。\"},\n",
    "    {\"speaker_1\": \"嗯。\"},\n",
    "    {\"speaker_2\": \"一部搞笑的电影。\"},\n",
    "    {\"speaker_1\": \"一部搞笑的。\"}\n",
    "]\n",
    "text = \" \" + \"\\n \".join([f\"{k}:{v}\" for item in dialog for k, v in item.items()]) + \"\\n\"\n",
    "prompt_diag = [\n",
    "    {\"speaker_1\": \"并且我们还要进行每个月还要考核 笔试的话还要进行笔试，做个，当服务员还要去笔试了\"},\n",
    "    {\"speaker_2\": \"对啊，这真的很奇怪，就是 单纯的因，单纯自己工资不高，只是因为可能人家那个店比较出名一点，就对你苛刻要求\"},\n",
    "]\n",
    "prompt_text = \" \" + \"\\n \".join([f\"{k}:{v}\" for item in prompt_diag for k, v in item.items()]) + \"\\n\"\n",
    "\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate speech based on the following description.\\n\",\n",
    "    \"text\": text,\n",
    "    \"use_spk_emb\": True,\n",
    "    \"prompt_wav_path\": [\n",
    "        \"data/wavs/CTS-CN-F2F-2019-11-11-423-012-A.wav\",\n",
    "        \"data/wavs/CTS-CN-F2F-2019-11-11-423-012-B.wav\"\n",
    "    ],\n",
    "    \"prompt_text\": prompt_text\n",
    "}\n",
    "\n",
    "response = model.speech_generation(**messages, **decode_args, output_wav_path='output/podcast.wav')\n",
    "logger.info(f\"Generated Response: {response}\")\n",
    "display(Audio('output/podcast.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Premium Timbre Library - IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 200,\n",
    "}\n",
    "instruction = {\n",
    "    \"IP\": \"灵小甄\"\n",
    "}\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate speech based on the following description.\\n\",\n",
    "    \"text\": \"这款产品的名字，叫变态坑爹牛肉丸。\",\n",
    "    \"instruction\": instruction,\n",
    "    \"use_zero_spk_emb\": True\n",
    "}\n",
    "response =  model.speech_generation(**messages, **decode_args, output_wav_path='output/ip.wav')\n",
    "display(Audio('output/ip.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Timbre Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 200,\n",
    "}\n",
    "instruction = {\n",
    "    \"风格\": \"这是一种ASMR耳语，属于一种旨在引发特殊感官体验的创意风格。这个女性使用轻柔的普通话进行耳语，声音气音成分重。音量极低，紧贴麦克风，语速极慢，旨在制造触发听者颅内快感的声学刺激。\"\n",
    "}\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate speech based on the following description.\\n\",\n",
    "    \"text\": \"我会一直在这里陪着你，直到你慢慢、慢慢地沉入那个最温柔的梦里……好吗？\",\n",
    "    \"instruction\": instruction,\n",
    "    \"use_zero_spk_emb\": True\n",
    "}\n",
    "response = model.speech_generation(**messages, **decode_args, output_wav_path='output/style.wav')\n",
    "display(Audio('output/style.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "libroFormatter": "formatter-string"
   },
   "source": [
    "# TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 200,\n",
    "    \"cfg\": 4.5,\n",
    "    \"sigma\": 0.3,\n",
    "    \"temperature\": 2.5\n",
    "}\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate audio events based on given text.\\n\",\n",
    "    \"text\": \"Thunder and a gentle rain\",\n",
    "}\n",
    "response = model.speech_generation(**messages, **decode_args, output_wav_path='output/tta.wav')\n",
    "logger.info(f\"Generated Response: {response}\")\n",
    "display(Audio('output/tta.wav'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# BGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 400,\n",
    "}\n",
    "attr = {\n",
    "    \"Genre\": \"电子舞曲.\",\n",
    "    \"Mood\": \"自信 / 坚定.\",\n",
    "    \"Instrument\": \"架子鼓.\",\n",
    "    \"Theme\": \"节日.\",\n",
    "    \"Duration\": \"30s.\"\n",
    "}\n",
    "text = \" \" + \" \".join([f\"{key}: {value}\" for key, value in attr.items()])\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate music based on the following description.\\n\",\n",
    "    \"text\": text,\n",
    "}\n",
    "response = model.speech_generation(**messages, **decode_args, output_wav_path='output/bgm.wav')\n",
    "logger.info(f\"Generated Response: {response}\")\n",
    "display(Audio('output/bgm.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Speech + BGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 200,\n",
    "}\n",
    "instruction = {\n",
    "    \"BGM\": {\"Genre\": \"当代古典音乐.\", \"Mood\": \"温暖 / 友善.\", \"Instrument\": \"电吉他\", \"Theme\": \"节日.\", \"SNR\": 10.0, \"ENV\": None}\n",
    "}\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate speech based on the following description.\\n\",\n",
    "    \"text\": \"此次业绩下滑原因，可归结为企业停止服务某些品牌，而带来的负面影响。\",\n",
    "    \"use_spk_emb\": True,\n",
    "    \"instruction\": instruction,\n",
    "    \"prompt_wav_path\": \"data/wavs/00000309-00000300.wav\",\n",
    "}\n",
    "response = model.speech_generation(**messages, **decode_args, output_wav_path='output/speech_bgm.wav')\n",
    "logger.info(f\"Generated Response: {response}\")\n",
    "display(Audio('output/speech_bgm.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# Speech + Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "isLargeOutputDisplay": true,
    "libroFormatter": "formatter-string"
   },
   "outputs": [],
   "source": [
    "decode_args = {\n",
    "    \"max_decode_steps\": 200,\n",
    "}\n",
    "instruction = {\n",
    "    \"BGM\": {\"ENV\": \"Birds chirping\", \"SNR\": 10.0, \"Genre\": None, \"Mood\": None, \"Instrument\": None, \"Theme\": None}\n",
    "}\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate speech based on the following description.\\n\",\n",
    "    \"text\": \"此次业绩下滑原因，可归结为企业停止服务某些品牌，而带来的负面影响。\",\n",
    "    \"use_spk_emb\": True,\n",
    "    \"instruction\": instruction,\n",
    "    \"prompt_wav_path\": \"data/wavs/00000309-00000300.wav\",\n",
    "}\n",
    "response = model.speech_generation(**messages, **decode_args, output_wav_path='output/speech_sound.wav')\n",
    "logger.info(f\"Generated Response: {response}\")\n",
    "display(Audio('output/speech_sound.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Text Normalization (TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The Text Norm feature is not supported for MoE models.\n",
    "decode_args = {\n",
    "    \"max_decode_steps\": 200,\n",
    "}\n",
    "messages = {\n",
    "    \"prompt\": \"Please generate speech based on the following description.\\n\",\n",
    "    \"text\": \"化学反应方程式：\\\\ce{2H2 + O2 -> 2H2O}\",\n",
    " }\n",
    "\n",
    "response = model.generation(**messages, **decode_args)\n",
    "logger.info(f\"Generated Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
